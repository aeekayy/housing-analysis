{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousingTest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpeQVut85VpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9923fc0c-5ad0-4356-cdd2-4ee5d47d0dc8"
      },
      "source": [
        "# Source https://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib\n",
        "\n",
        "train=pd.read_csv('sample_data/redfin_2020-07-18-14-38-28.csv',encoding='utf-8')\n",
        "train.drop(['sale_type','sold_date','status','next_open_house_start_time','next_open_house_end_time','house_url','source','mls_no','favorite','interested'], axis=1, inplace = True)\n",
        "# exclude objects\n",
        "train_numerical = train.select_dtypes(exclude=['object'])\n",
        "train_numerical.fillna(0,inplace = True)\n",
        "train_categoric = train.select_dtypes(include=['object'])\n",
        "train_categoric.fillna('NONE',inplace = True)\n",
        "train_data = train_numerical.merge(train_categoric, left_index = True, right_index = True)\n",
        "train.head()\n",
        "\n",
        "# Find outliers\n",
        "clf = IsolationForest(max_samples = 100, random_state = 42)\n",
        "clf.fit(train_numerical)\n",
        "y_noano = clf.predict(train_numerical)\n",
        "y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
        "y_noano[y_noano['Top'] == 1].index.values\n",
        "\n",
        "train_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
        "train_numerical.reset_index(drop = True, inplace = True)\n",
        "train_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
        "train_categoric.reset_index(drop = True, inplace = True)\n",
        "train = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
        "train.reset_index(drop = True, inplace = True)\n",
        "\n",
        "col_train_num = list(train_numerical.columns)\n",
        "col_train_num_bis = list(train_numerical.columns)\n",
        "col_train_cat = list(train_categoric.columns)\n",
        "col_train_num_bis.remove('price')\n",
        "mat_train = np.matrix(train_numerical)\n",
        "mat_new = np.matrix(train_numerical.drop('price',axis = 1))\n",
        "mat_y = np.array(train.price)\n",
        "prepro_y = MinMaxScaler()\n",
        "prepro_y.fit(mat_y.reshape(43,1))\n",
        "prepro = MinMaxScaler()\n",
        "prepro.fit(mat_train)\n",
        "prepro_test = MinMaxScaler()\n",
        "prepro_test.fit(mat_new)\n",
        "train_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)\n",
        "train[col_train_num] = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)\n",
        "\n",
        "COLUMNS = col_train_num\n",
        "FEATURES = col_train_num_bis\n",
        "LABEL = \"price\"\n",
        "FEATURES_CAT = col_train_cat\n",
        "engineered_features = []\n",
        "for continuous_feature in FEATURES:\n",
        "    engineered_features.append(\n",
        "        tf.feature_column.numeric_column(continuous_feature))\n",
        "for categorical_feature in FEATURES_CAT:\n",
        "    sparse_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "        categorical_feature, hash_bucket_size=1000)\n",
        "engineered_features.append(tf.feature_column.embedding_column(categorical_column=sparse_column, dimension=16,combiner=\"sum\"))\n",
        "\n",
        "# Build the training set and the prediction set\n",
        "training_set = train[FEATURES + FEATURES_CAT]\n",
        "prediction_set = train.price\n",
        "# Split the train and prediction sets into test train sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,\n",
        "                                                    prediction_set, test_size=0.2, random_state=42)\n",
        "y_train = pd.DataFrame(y_train, columns = [LABEL])\n",
        "training_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)\n",
        "y_test = pd.DataFrame(y_test, columns = [LABEL])\n",
        "testing_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)\n",
        "\n",
        "training_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)\n",
        "testing_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)\n",
        "def input_fn_new(data_set, training = True):\n",
        "    continuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
        "    \n",
        "    categorical_cols = {k: tf.SparseTensor(\n",
        "        indices=[[i, 0] for i in range(data_set[k].size)], values = data_set[k].values, dense_shape = [data_set[k].size, 1]) for k in FEATURES_CAT}\n",
        "# Combines the dictionaries of the categorical and continuous features\n",
        "    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\n",
        "    \n",
        "    if training == True:\n",
        "        # Converts the label column into a constant Tensor.\n",
        "        label = tf.constant(data_set[LABEL].values)\n",
        "# Outputs the feature columns and labels\n",
        "        return feature_cols, label\n",
        "    \n",
        "    return feature_cols\n",
        "# Builds the Model Framework\n",
        "regressor = tf.estimator.DNNRegressor(feature_columns = engineered_features, \n",
        "                                          activation_fn = tf.nn.relu, hidden_units=[250, 100, 50])\n",
        "categorical_cols = {k: tf.SparseTensor(indices=[[i, 0] for i in range(training_set[k].size)], values = training_set[k].values, dense_shape = [training_set[k].size, 1]) for k in FEATURES_CAT}\n",
        "\n",
        "regressor.evaluate(input_fn = lambda: input_fn_new(training_set) , steps=10000)\n",
        "\n",
        "ev = regressor.evaluate(input_fn=lambda: input_fn_new(testing_set, training = True), steps=1)\n",
        "loss_score = ev[\"loss\"]\n",
        "print(\"Final Loss on the testing set: {0:f}\".format(loss_score))\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import itertools\n",
        "ev = regressor.evaluate(input_fn=lambda: input_fn_new(testing_set, training = True), steps=1)\n",
        "loss_score = ev[\"loss\"]\n",
        "print(\"Final Loss on the testing set: {0:f}\".format(loss_score))\n",
        "print(pd.DataFrame(prepro.inverse_transform(testing_set.select_dtypes(exclude=['object'])), columns = [COLUMNS]).price)\n",
        "reality = pd.DataFrame(prepro.inverse_transform(testing_set.select_dtypes(exclude=['object'])), columns = [COLUMNS]).price\n",
        "y = regressor.predict(input_fn=lambda: input_fn_new(testing_set))\n",
        "predictions = list(itertools.islice(y, testing_set.shape[0]))\n",
        "predictions = pd.DataFrame(prepro_y.inverse_transform(np.array(predictions).reshape(263,1)))\n",
        "matplotlib.rc('xtick', labelsize=30) \n",
        "matplotlib.rc('ytick', labelsize=30)\n",
        "fig, ax = plt.subplots(figsize=(15, 12))\n",
        "plt.style.use('ggplot')\n",
        "plt.plot(predictions.values, reality.values, 'ro')\n",
        "plt.xlabel('Predictions', fontsize = 30)\n",
        "plt.ylabel('Reality', fontsize = 30)\n",
        "plt.title('Predictions x Reality on dataset Test', fontsize = 30)\n",
        "ax.plot([reality.min(), reality.max()], [reality.min(), reality.max()], 'k--', lw=4)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6dnb35wc\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp6dnb35wc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_iforest.py:281: UserWarning: max_samples (100) is greater than the total number of samples (57). max_samples will be set to n_samples for estimation.\n",
            "  % (self.max_samples, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp6dnb35wc, running initialization to evaluate.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-03T15:55:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1000/10000]\n",
            "INFO:tensorflow:Evaluation [2000/10000]\n",
            "INFO:tensorflow:Evaluation [3000/10000]\n",
            "INFO:tensorflow:Evaluation [4000/10000]\n",
            "INFO:tensorflow:Evaluation [5000/10000]\n",
            "INFO:tensorflow:Evaluation [6000/10000]\n",
            "INFO:tensorflow:Evaluation [7000/10000]\n",
            "INFO:tensorflow:Evaluation [8000/10000]\n",
            "INFO:tensorflow:Evaluation [9000/10000]\n",
            "INFO:tensorflow:Evaluation [10000/10000]\n",
            "INFO:tensorflow:Inference Time : 5.63858s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-03-15:55:39\n",
            "INFO:tensorflow:Saving dict for global step 0: average_loss = 0.48328406, global_step = 0, label/mean = 0.5530018, loss = 0.4833469, prediction/mean = -0.077334404\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp6dnb35wc, running initialization to evaluate.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-03T15:55:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Inference Time : 0.21301s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-03-15:55:39\n",
            "INFO:tensorflow:Saving dict for global step 0: average_loss = 0.48447365, global_step = 0, label/mean = 0.5750201, loss = 0.48447365, prediction/mean = -0.07836207\n",
            "Final Loss on the testing set: 0.484474\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp6dnb35wc, running initialization to evaluate.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-03T15:55:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Inference Time : 0.20160s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-03-15:55:40\n",
            "INFO:tensorflow:Saving dict for global step 0: average_loss = 0.3122681, global_step = 0, label/mean = 0.5750201, loss = 0.3122681, prediction/mean = 0.05846691\n",
            "Final Loss on the testing set: 0.312268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-99ec5cce10f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mloss_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final Loss on the testing set: {0:f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0mreality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5273\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5274\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3584\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3587\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3588\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    966\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot label index with a null key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mOtherwise\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \"\"\"\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    }
  ]
}